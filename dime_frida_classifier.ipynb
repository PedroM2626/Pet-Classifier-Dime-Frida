{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4d2b24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6dc0078d",
   "metadata": {},
   "source": [
    "# Configuração Inicial e Importações\n",
    "Configura o logger para depuração e importa as bibliotecas necessárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f79d26d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') # Usar o backend 'Agg' para evitar problemas de exibição e salvamento\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import keras\n",
    "from matplotlib.pyplot import imshow\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "# Configurar o logger\n",
    "logging.basicConfig(filename='debug_log.txt', level=logging.DEBUG,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "logging.info(\"Script dime_frida_classifier.py iniciado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe643e23",
   "metadata": {},
   "source": [
    "# Funções Auxiliares\n",
    "Define funções para carregar imagens e gerar mapas de calor Grad-CAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb106a1d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# helper function to load image and return it and input vector\n",
    "def get_image(path):\n",
    "    try:\n",
    "        img = image.load_img(path, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = preprocess_input(x)\n",
    "        return img, x\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Aviso: Não foi possível carregar a imagem {path}. Erro: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last convolutional layer as well as the output predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last convolutional layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen) with respect\n",
    "    # to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array by \"how important this channel is\"\n",
    "    # with respect to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304c506c",
   "metadata": {},
   "source": [
    "# Configurações do Dataset\n",
    "Define o caminho raiz do dataset e as categorias de imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03535c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configurações do Dataset ---\n",
    "root = r'c:\\Users\\pedro\\Downloads\\my_precious-dataset\\my_precious-dataset'\n",
    "logging.info(f\"Caminho root configurado: {root}\")\n",
    "train_split = 0.8 # 80% para treinamento\n",
    "val_split = 0.2   # 20% para validação\n",
    "\n",
    "# Definir as categorias explicitamente\n",
    "categories = [os.path.join(root, 'Dime'), os.path.join(root, 'Frida')]\n",
    "category_names = ['Dime', 'Frida'] # Nomes das classes para exibição\n",
    "\n",
    "logging.info(f\"Categorias encontradas: {category_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52980b89",
   "metadata": {},
   "source": [
    "# Carregamento e Pré-processamento dos Dados\n",
    "Carrega as imagens, as pré-processa e divide em conjuntos de treinamento, validação e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0d614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Carregamento e Pré-processamento dos Dados ---\n",
    "data = []\n",
    "logging.info(f\"Iniciando carregamento de imagens para as categorias: {category_names}\")\n",
    "for c_idx, category_path in enumerate(categories):\n",
    "    images = [os.path.join(dp, f) for dp, dn, filenames\n",
    "              in os.walk(category_path) for f in filenames\n",
    "              if os.path.splitext(f)[1].lower() in ['.jpg','.png','.jpeg']]\n",
    "    logging.info(f\"Número de imagens encontradas em {category_path}: {len(images)}\")\n",
    "    for img_path in images:\n",
    "        img, x = get_image(img_path)\n",
    "        if img is not None and x is not None:\n",
    "              data.append({'x':x, 'y':c_idx})\n",
    "\n",
    "logging.info(f\"Comprimento final da lista de dados após o carregamento: {len(data)}\")\n",
    "\n",
    "# Contar o número de classes\n",
    "num_classes = len(category_names)\n",
    "\n",
    "# Randomizar a ordem dos dados\n",
    "random.shuffle(data)\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento, validação e teste (70%, 15%, 15%)\n",
    "random.shuffle(data)\n",
    "train_split_ratio = 0.7\n",
    "val_split_ratio = 0.15\n",
    "\n",
    "idx_train = int(len(data) * train_split_ratio)\n",
    "idx_val = int(len(data) * (train_split_ratio + val_split_ratio))\n",
    "\n",
    "train = data[:idx_train]\n",
    "val = data[idx_train:idx_val]\n",
    "test = data[idx_val:]\n",
    "\n",
    "# Separar dados para rótulos\n",
    "x_train_list = []\n",
    "y_train_list = []\n",
    "for t in train:\n",
    "    x_train_list.append(t[\"x\"])\n",
    "    y_train_list.append(t[\"y\"])\n",
    "x_train = np.array(x_train_list)\n",
    "y_train = np.array(y_train_list)\n",
    "\n",
    "x_val_list = []\n",
    "y_val_list = []\n",
    "for t in val:\n",
    "    x_val_list.append(t[\"x\"])\n",
    "    y_val_list.append(t[\"y\"])\n",
    "x_val = np.array(x_val_list)\n",
    "y_val = np.array(y_val_list)\n",
    "\n",
    "x_test_list = []\n",
    "y_test_list = []\n",
    "for t in test:\n",
    "    x_test_list.append(t[\"x\"])\n",
    "    y_test_list.append(t[\"y\"])\n",
    "x_test = np.array(x_test_list)\n",
    "y_test = np.array(y_test_list)\n",
    "\n",
    "# Normalizar dados\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_val = x_val.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "# Converter rótulos para vetores one-hot\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Resumo\n",
    "print(\"Carregadas %d imagens de %d categorias\"%(len(data), num_classes))\n",
    "logging.info(f\"Número de amostras de treinamento: {len(train)}\")\n",
    "logging.info(f\"Número de amostras de validação: {len(val)}\")\n",
    "logging.info(f\"Número de amostras de teste: {len(test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c7da7a",
   "metadata": {},
   "source": [
    "# Construção e Treinamento do Modelo (VGG16 com Transfer Learning)\n",
    "Configura e treina um modelo VGG16 para classificação de imagens usando transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9677622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Construção e Treinamento do Modelo (VGG16 com Transfer Learning) ---\n",
    "print(\"\\n--- Usando VGG16 para Transfer Learning ---\")\n",
    "vgg = keras.applications.VGG16(weights='imagenet', include_top=True)\n",
    "\n",
    "inp = vgg.input\n",
    "new_classification_layer = Dense(num_classes, activation='softmax')\n",
    "out = new_classification_layer(vgg.layers[-2].output)\n",
    "model_new = Model(inp, out)\n",
    "\n",
    "# Congelar todas as camadas, exceto a última\n",
    "for l, layer in enumerate(model_new.layers[:-1]):\n",
    "    layer.trainable = False\n",
    "for l, layer in enumerate(model_new.layers[-1:]):\n",
    "    layer.trainable = True\n",
    "\n",
    "model_new.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_new.summary()\n",
    "\n",
    "logging.info(f\"Shape de x_train: {x_train.shape}\")\n",
    "logging.info(f\"Shape de y_train: {y_train.shape}\")\n",
    "logging.info(f\"Shape de x_val: {x_val.shape}\")\n",
    "logging.info(f\"Shape de y_val: {y_val.shape}\")\n",
    "\n",
    "history2 = model_new.fit(x_train, y_train,\n",
    "                         batch_size=128,\n",
    "                         epochs=10,\n",
    "                         validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea50716",
   "metadata": {},
   "source": [
    "# Avaliação do Modelo\n",
    "Avalia o desempenho do modelo treinado no conjunto de testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5612fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Avaliação do Modelo ---\n",
    "loss, accuracy = model_new.evaluate(x_test, y_test, verbose=0)\n",
    "print('Perda no teste:', loss)\n",
    "print('Precisão no teste:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6128a93",
   "metadata": {},
   "source": [
    "# Análise de Imagem da Pasta 'tests'\n",
    "Processa imagens da pasta 'tests', faz previsões e salva os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e565a1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Análise de Imagem da Pasta 'tests' ---\n",
    "logging.info(\"--- Análise de Imagens da Pasta 'tests' ---\")\n",
    "test_images_dir = os.path.join(root, 'tests')\n",
    "output_dir = os.path.join(root, 'results')\n",
    "\n",
    "# Certificar-se de que o diretório de saída existe\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "image_files = [f for f in os.listdir(test_images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "if not image_files:\n",
    "    logging.warning(f\"Nenhuma imagem encontrada na pasta de testes: {test_images_dir}\")\n",
    "    print(f\"Nenhuma imagem encontrada na pasta de testes: {test_images_dir}\")\n",
    "else:\n",
    "    for image_filename in image_files:\n",
    "        img_path = os.path.join(test_images_dir, image_filename)\n",
    "        logging.debug(f\"Processando imagem de teste: {img_path}\")\n",
    "        img, img_processed = get_image(img_path)\n",
    "\n",
    "        if img is not None and img_processed is not None:\n",
    "            img_processed = np.expand_dims(img_processed, axis=0)\n",
    "            prediction = model_new.predict(img_processed)\n",
    "            predicted_class_idx = np.argmax(prediction)\n",
    "            predicted_class_name = category_names[predicted_class_idx]\n",
    "\n",
    "            # Salvar as imagens\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(f\"Predicted: {predicted_class_name}\")\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "            output_filename = os.path.splitext(image_filename)[0] + \".png\"\n",
    "            full_output_path = os.path.join(output_dir, output_filename)\n",
    "            try:\n",
    "                plt.savefig(full_output_path)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Erro ao salvar a imagem {image_filename} em {full_output_path}: {e}\")\n",
    "            plt.close(fig) # Fechar a figura para liberar memória\n",
    "        else:\n",
    "            print(f\"Não foi possível carregar ou processar a imagem de teste: {img_path}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
